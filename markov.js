// Markov chain generator code for Thought and Reply
class MarkovChain {
    constructor(sourceText) {
        this.sourceText = sourceText;
        this.wordDict = {};
        this.startWords = [];
        this.buildChain();
    }

    buildChain() {
        const sentences = this.sourceText.match(/[^.!?]+[.!?]+/g) || [];
        sentences.forEach(sentence => {
            const words = sentence.trim().split(/\s+/);
            if (words.length > 0) {
                const firstWord = words[0].toLowerCase();
                if (!firstWord.match(/^[^a-zA-Z0-9]/)) { // Ensure the first word does not start with non-alphanumeric characters
                    this.startWords.push(firstWord);
                }
            }
            for (let i = 0; i < words.length - 1; i++) {
                const word = words[i].toLowerCase();
                const nextWord = words[i + 1].toLowerCase();
                if (!this.wordDict[word]) {
                    this.wordDict[word] = [];
                }
                this.wordDict[word].push(nextWord);
            }
        });
    }

    generateText(minWords, maxWords) {
        const numWords = Math.floor(Math.random() * (maxWords - minWords + 1)) + minWords;
        let currentWord = this.startWords[Math.floor(Math.random() * this.startWords.length)];
        let result = [currentWord];

        for (let i = 0; i < numWords - 1; i++) {
            if (this.wordDict[currentWord]) {
                const nextWords = this.wordDict[currentWord];
                currentWord = nextWords[Math.floor(Math.random() * nextWords.length)];
                result.push(currentWord);
            } else {
                break;
            }
        }

        return result.join(' ');
    }

    generateMultipleTexts() {
        const numTexts = Math.random() < 0.5 ? 1 : 2; // Randomly decide to generate one or two texts
        let texts = [];
        for (let i = 0; i < numTexts; i++) {
            let text = this.generateText(10, 20); // Generate text with variable length between 10 and 20 words
            text = text.charAt(0).toUpperCase() + text.slice(1); // Capitalize the first letter
            texts.push(text);
        }
        return texts.join(numTexts === 2 ? '\n\n' : '');
    }
}


// Load the source texts for Thought and Reply
const thoughtSourceText = `Hi, all! My name is PD Edgar; I'm a 1st-Year Texts & Tech student (MA Media studies, MFA poetry from Bama) with interests in digital/e-literature, poetry culture, book history, and creative writing. I've been experimenting with computer-assisted writing since 2021, and Aug.1 of this year I launched re•mediate, a journal specifically as a home for experiments and debates in computer-assisted/generated writing! I'm super excited to deepen my knowledge this semester alongside everyone here. 
I was super excited to start with Bitstreams, and even more delighted that the author bookends our readings with examples of creative writing specifically— a working writer's many drafts, and the left-behind text-artifacts of TS Eliot and Toni Morrison. The materiality / haunting of the print, the digital ,and the in-between remediations, duplications, transcriptions, marginalia, etc. all deepen what it means for any "poem" to exist, etc., as well as copyright concerns and archivism! I'm worried about the different email addresses I've had over the years that are slowly defuncting— my college Microsoft account, the chance that I could lose access to my email, or the 10-year deletion warning on UCF's records— all highlight this. I hope all poets who pass away in this century have their passwords written down so that the world might not lose their Notesapp, their Notion or Ulysses app, etc. 
Though large language models are material somewhere, via servers and energy expense, the "anywhereness" of that reality contributes to the kind of ephemerality I feel around Chat conversations. I may be interacting with "Chat," in a way that approximates the immediacy of real conversation, but the memory of Chat is totally up to the decisions of the host—how long those conversations are hosted before they are erased. Should I get a receipt printer and rig it to print all my chats? My texts, messages, discord threads, etc, that the record of myself may not perish from the earth? And yet, on the floor of my car, my receipts turn white under the Florida sun, the record of my Winn-Dixie grocery run only yet preserved in the ephemerApp, the ephemerecord of my transaction, in the bank statements I've clicked to go paperless with. 
In the interest of equity, I tried the same script with both CoPilot, which I have very little familiarity with, and Eliza, beginning with the latter. I pitched the deadline as the opening dilemma, and found both of them regurgitating my thoughts to me with varying degrees of well-spokenness. CoPilot asked maybe some better, more probing questions, but Eliza seemed to invite the kind of silences that open up a psychotherapy session better than CoPilot, which seemed more solution-oriented. CoPilot acted more receptive to the story I told, and it made me "feel" more like I was heard more than Eliza could.
In all, I'm really intrigued by the comparative work that we can do between different chatbots and a parser-based chat, and I'd like to learn more about how to write parser-based "chats" like Eliza is perceived. Is to play with Eliza (provocation) to co-generate an interactive digital fiction?  
Alia, HI! It's good to meet you again; I think I shared a Zoom room with you at the ELO conference over the summer. 
I really resonated with what you had to say about AI ("I do not believe AI can do any more than I tell it to do"): one of the biggest reasons that I'm not really afraid of these programs as a concept is because it doesn't seem like we're programming a full agent—a computer that can say and do whatever it wants, without prompting— and I'm not sure that we could achieve it even if that is the goal with AGI (General Intelligence). Such an effort seems to reduce the consciousness of an individual to pure language and information, a belief I don't hold—even to pair an AI with a mechanical body ignores that an animal body is a sensing biome, not a machine. Generative AI is a tool, and humans decide what the tool can be useful for. 
You also recall the "Academy" and "selfish views of 'their work'" and I once again resonate with that acknowledgement: specifically, the indvidualist vs. communitarian understandings of knowledge production. Though I participate in academia, as we all are, I would hold that the knowledge I end up producing depends on not just the citable conversations and resources I have, but all of the moments in between the books and articles I read: the conversations I have in class and with my advisors, the discussions I have with family about my work, and the effect scrolling through a few different social media feeds has on my worldview. Many of those interactions are non-quantifiable and yet have an impact on our work, and that communitarian view I believe could translate as a piece of the puzzle when we discuss whether AI-generated text is "thieving" or some sort of "forced collusion" between all possible sources of knowledge to generate a probable outcome. I'm sure that my thoughts will be contextualized some more down the road, especially in regards to future readings, but for now, I appreciate that you and I are having similar questions. Looking forward to engaging more! 
Chani (and Justin)! I love where this conversation is going about deception and "gaslight"ing— Justin, when you said "Is that possibility for enchantment by today’s algorithms born of the same “stuff” as ELIZA? This is a tough pill for me to swallow," my mind went racing to the history of deception and trickery. "Gaslighting" is a bad-faith behavior/way to communicate with someone, but I wonder if the problem with chatbots is that they take advantage of the way people engage in good faith with a computer that's just running statistical probability math on what an appropriate response would be.
I was interested in if there were a connection between probabilistic systems and deception, and I realized that it's a lot of "most likely" answers and "magic" tricks that depend on a human's capacity to perceive an appeal to the probable outcome as a kind of magic. Take for example, the math riddle that depends on a simple trick (digits in the first 10 multiples of 9 add up to 9) to appear like mind-reading. The probability is built into the trick, but if you don't notice the pattern, or know how the trick works, anyone can come off as a mentalist. With other tricks, like "green glass doors" or "4 is Cosmic," we're willing to engage with the person telling the riddle as long as we don't feel like the rules are being changed on us, as long as we feel like we're not being deceived. 
These ethics come into play with art and writing, it seems to me, because people who believe 1) Ai art is bad/wrong and 2) that they can always tell when art is made by Ai get really freaked out when they feel that their experience of being online, having a curated page, has been toyed with— that they have been deceived into liking AI art. AI feels like a deceiver to them. It's the same reason we feel cheated when a movie that uses computer generation is too obvious— the edges are too sharp. 
Interested how this idea might be developed further! But my understanding is that the capacity for enchantment is inside each of us lol ! for better or for worse! 
Justin, I love these questions at the end of your comment! I'm stuck at the moment on how much of a Chat's output is truly "expressive," and if that makes the difference between a math computer and a text-generator. In the purest sense, computational/probabilistic machines like CoPilot are just calculating "given the meanings provided to me, the best probable combination of meanings I can return are..." and those combinations of meanings are undoubtedly provided by real live people who did the work to combine those meanings and publish them. There's a middleman at fault, the companies who sold all of those combinations of meanings to the AI companies to train them, or whose ToS provided for the AI companies to scrape from them, without creators' consent. But if CoPilot's just combining these meanings together to match my input with acceptable output, is anything it writes "expressive" at all to begin with? It's not writing from "experience," but neither (to play on William Blake) is the text generated by an LLM based in any "innocence". The negative outputs of an LLM are to be blamed on the corpus, so it would be unfair not to attribute the positive outputs to the corpus as well. The question "To what extent did we exist in vacuums as creators prior to all this" is what I brought up in a reply just now to Alia— that even our most well-cited research may also yet be indebted to the conversations we engage in, classes we take, and unquantifiable experiences we have outside of the research — which is something Chat can't share. What would it mean to act in "Malicious Compliance" to the imperative to cite all sources in any paper? Lots to consider; thanks for bringing these up! 
Michael, great to meet you, and I appreciate you bringing this up!! A lot of the ways folks have engaged with ELIZA have been with the specific intent to speak through to the machine, to "jailbreak" the program or to "red team" CoPilot, ChatGPT, Gemini, etc., to find the faults. But it seems like ELIZA is effective and holds the veil well when interacted with upon the premise that ELIZA "is" a CBT talk-psychotherapist. 
Emilie, I love what you bring up about manners and politeness because it recalls for me (1) the ways that fences have been put up in terms of how LLMs are "allowed" to respond to humans, or rather trained to respond to inputs, even negative inputs. (2) As well, it brings to mind the meme of folks saying that they treat their Alexas and other [Chat]Bots kindly and politely so that on the day an AI takes over the world, perhaps it will remember our kindness to them and reciprocate it— bringing an "eye for an eye" or a "golden rule" ethic to computer-human interaction. If robots are to be treated like consciousnesses, and if a goal of AI companies is such, what agency should we afford them in our conversations with them? What about the "trust factor" in conversations with these models reverts adults to the annoying, precocious kind of "ask "why" until they break" model that toddlers and children use to drive their fellow humans up a wall? This sends me way back up to I think Chani, who used the word "gaslighting." 
Hello, y'all! Thriving in a condition of "information overload" this week— my mind is indexing everything I read finishing Bitstreams and processing the "Policeman's Beard is Algorithmically Constructed" + Bogost's articles on top of everything in the AI-written-work news cycle: Ted Chiang's New Yorker piece and the National Novel Writing Month's take on AI-written work. AND just the general blowback to AI in the culture. I'm writing a paper right now about this whole situation, and so for my poem I did with Co-Pilot what I've been doing with ChatGPT: testing its abilities to manage a couple poetry forms. If LLMs are language-patterning programs, what can and can't they handle? And what's the discourse they use to talk around poetry, too? 
One of my observations is that from my interactions, the smallest unit of language for the LLMs is not a phoneme or letter, but any given word. This makes something like erasure poetry really difficult for the models! Easy patterns like forms that depend on rhymes, lineation and punctuation structures are pretty straightforward, but erasure is an exercise in friction against the entire logic of a piece of text to whittle/chip it down into something (hopefully) totally new. I liked the poem CoPilot suggested after a few iterations, but when I asked it to break down the text, we got really thin and watery and couldn't handle BOTH erasure AND syllable count at the same time. 
Spring whispers through the frost-laden air / I step out / the world still wrapped in the quiet of dawn / my breath mingles with the mist / my dog at my side / paws padding softly on the dew-kissed ground / the sky blushes with the first light / trees stretch their limbs / shaking off winter’s slumber / each step a conversation with the earth / the cold nips at my cheeks / a reminder of the night’s lingering embrace / yet the promise of warmth stirs within / my dog sniffs the air / sensing the subtle shift / the world begins to wake / but for now / it is ours alone / a sacred silence / a moment of pure embodiment / man and dog / heartbeats in sync / walking the edge of night and day / spring’s gentle arrival / a symphony of stillness / a dance of life unfolding / quietly / beautifully / in the early morning light
Doing this practice along with Bitstreams made me think about the cost and work it takes to preserve these items that are so ephemeral— all the interactions with LLMs etc., the sheer amount of content generate-able, all the images that aren't quite what I want: Kirschenbaum spends a whole chapter talking about the loss of the process of moving poetry towards a "final" form. What I like about my own process with ChatGPT is that I treat my interaction pedagogically; I explain what changes I'd like and why so I can track with my own thoughts as I move. But what if those chats disappear, I not having stored them? *UPDATE: THEY DID I CLOSED THE TAB I sent an AI-generated video monologue I saw on Twitter of AI-Trump converting to eastern spirituality, leaving politics, and becoming "the best shaman" to a far-right studies researcher I know at Bama, but when I came back to watch it again, the post had been deleted. I hoped he had saved it; I regretted not. But then I'd be storing AI slop on my computer, too, and inexorably we return to the question of "memory" "RAM" "energy" and "environmental/climate" concerns. When I run AI, I think "would it be worth not turning on the lights in my apartment tomorrow? Would that be a suitable offset?" 
Last, my thoughts return to the discussions of Bookishness and the affordances of desktop publishing in the composition and production of literature. If I hadn't been accepted to this program, I'd be a book designer at a University press somewhere, doing that process. (You know, general print publishing and the integrated nature of that global supply chain has an outsized carbon footprint of its own, right?) I think everyone should learn a little InDesign, the way (lol) Steve Jobs said everyone should learn to code (p. 66: the power of the computer was precisely in the degree of control it promised him). Those kinds of literacies "visibilize" all the little invisible processes we take for granted when we begin to take pen to paper, and just the difference in ability/generosity between New Directions' production team and BloodAxe Books' meant the difference between the reader's experience of Brathwaite's Middle Passages (circa p. 58).
I return to Henrickson's suggestion that the text only has a kind of cultural impact upon its perception by a reader : when code and output interact with the world. What does it mean when the reader-response to AI-generated work is revolt? Will collective outrage yield collective action? Happy Labor Day, ~ PD
Hello! I made two videos with Runway: one animation of a vorticist print image I was working with last week, and one slow zoom based on two pictures I took in a sulfur-poisoned forest at the top of Volcan Mombacho back home. Runway was really able to handle the key framing between the two pictures, basically filling in the five seconds between a wide shot and a close-up, and in the left-side of the video you do get a little bit of the sense of the cloud moving over the mountain saddle. 
The other video I had it generate I gave it one simple instruction based on the image provided (attached here as well): "Animate". What I love about asking AI to handle abstracted or modern art is that it goes against the entire grain of these image generation protocols (as far as I can tell), which has been working to get to finer and more photorealistic representational images with clean transitions between them. The image that I'm working with is from BLAST, a Vorticist magazine by Wyndham Lewis, who also made the image I used.
What we get is an attempt at unlayering the lines and black blocks of the 2-d Image, hinting at how the Runway model is thinking about or parsing these video elements — into layers of images that can be separated out, filled in behind, and stretched along certain perspective lines. That's why the butterfly video that opened our readings for this week felt like they were moving along two separate planes: a plane of the grass, stretching forward up, and the butterfly, staying in place. The simpler the task here, at least using pre-existing footage, the better for the model. 
Watching The Wizard of AI, I really liked working through the Runway suggestion book (they have a little glossary of terms that they recommend you use) because I noticed a number of these features in the video essay. These sorts of AI videos, including PostHuman Cinema, feel collagistic, something that feels "found" and "rough" around the edges but does in fact depend quite a bit on the artist's sense for composition and their intuition and ability to imagine through the swath of possibility provided by excess— knowing what to cut out of a magazine, or knowing what to prompt from a model that purports to be able to imagine even the things no one has thought of before. What The Wizard of AI does for me is showcase how a video essay organized around narrative segmentation is actually able to deliver a stylistically-rich visual narrative to accompany the textual/aural one provided by the narrator/screenwriter. They're traceable too—the metaphor of "what goes on behind the curtain" is of course a nod to the Wizard of Oz, and so the image generation riffs on that with its own mistaken, hallucinatory qualities. In such, the videodoc enacts the very things the screenwriting purports to describe, which is a knack of good poetry (to me).
The end of Mitchell's book is a great place to land, here, because of these models' inability to attach meaning— to propriocept — is a creative limitation if you want to do one kind of art, but an expansive field of possibility if you want to make another kind of art. I fear, similar to near where The Wizard of AI ends, that the processes of specializing LLMs and generalizing them for a given purpose — this kind of multimodal, multimedia integration into integration — won't necessarily help these companies succeed. The everything machine is a false promise premised on the American ideal of the one-stop shop, the product to end all products, the infinite growth projection. I don't know if I've talked about this idea in this class before, but I'm always reminded of a cut scene in the 1971 (1971!!!) film Willy Wonka and the Chocolate Factory, wherein a man has programmed a computer to locate the remaining golden tickets. Two responses are given: "I won't tell; that would be cheating," and "what would a computer do with a lifetime supply of chocolate?" As early and as trivial as this seems, it cuts into the idea of machine vision in an opposite way to that of the Vision-Ultron dialectic: the machine is blasé, bored of our problems that don't concern it, which only precedes Marvin the Paranoid Android, in Hitchhiker's guide to the Galaxy, by 7 years. To the Golden-Ticket-Prediction machine, since it is presumed to have coded in ethics, WW&CF is an example of the "prediction is action" point Zylinska makes in chapter 6, and of the presumed valuable audience to that computational power: wealthy white investors in suits.
Hello! I struggled to innovate on the interface; so I asked chatGPT (as well as the AI-assist function inside of Open Processing) to perform some of the same convolutional layer visualizations that the Tensorflow.js tfjs-viz folder had going on! The reason I'm opening with this instead of with what I actually did is because my biggest question about Image-Text work is about the actual perceptual boundary between "Image" and "Text" with the neural network. 
MY datasets: 1) An anthology of Concrete poetry, 2) An anthology of Conceptual poetry, and 3) an anthology of Contemporary poetry. They're represented left-to-right here, but of course there were variations in this category— some of each looks like some of the other. 
I screenshotted 30 poems out of each section and built out the corpus this way, but I noticed immediately that there may be one kind of confounding variable as I worked with these different elements: FONT and Scan. the PDF I sourced the concrete poetry from all has a gray-page look compared to the others, and the serif vs. sans-serif element of each of these is consistent. I'd like to represent all of the work with enough variability to parse whether the algorithm is looking at the shape of the text (rectangles, triangles, columns), the symbols (often conceptual work contains math or asemic writing or is in a list format), or is perceiving the text itself— in which case the edges of a sans-serif vs. a serif font would come into play. 
I ended up training the models several times, and noticed that on my first go it was decent at identifying the works! As we went along, however, things got kinda worse. 
There's some interference as I began working within Open Processing that misidentifies almost all work I uploaded as a test image as either Contemporary or Conceptual: almost never as Concrete work— even work that VERY MUCH is concrete! 
Luckily, I was testing with images outside my dataset that I had control over fonts on: my own work. 
Ultimately, I got a confusion matrix that usually identified poems as conceptual or contemporary— and almost never ever guessed concrete, even with work that is DENSELY concrete, like the middle image here. This would be a  really fun project, and working with ChatGPT to Code the Open Processing interface has actually got me excited to learn code, fully convinced that I need to learn because of what IS possible, what I COULD do. I'm excited to keep agreeing with Littman on this front, and for future coursework where I do more of this ! Since this project could be taken further, I think, with better parameters and coding literacy on my part. 
Ok so... this assignment had me NERvous !! I went with a similar program to the demonstration, but instead of going with Genre and having users rate the books they'd read, I had ChatGPT list poetry collections written after 2000 and provide two "Subject" tags and two "Theme" tags for each work. Later on, I had GPT compile these sets of tags into a single "tags" line item, because.... 
The "Rate a book of poetry" function is not going to be helpful to anyone who's not reading poetry to begin with. So, what I did instead is flip the construction of the site so that the Titles are recommended based on the user's selection of Tags. It took me about 10-12 deployments of the project to get the project reworked from the initial demonstration to how I envisioned it in my head, and the last 5-6 of those were me trying to figure out how the heck to get the tags to show up across the screen instead of in a single column (using a 5-column table!). 
Check out: Discover a New Poet here!! Now for the reflection. The coding half of this project seems pretty straightforward— as long as you're comfortable with iteration and have some of the vocabulary to know what to ask for (I had to google what "cards" were because I was thinking about online shopping items and wanted the recommendations to display in individual boxes instead of as text), you can do about any simple development. This is the first time I've felt fully in control of a coding project and felt in control of ChatGPT's code. I think Littman would be extremely pleased, so thank you!! 
The JSON file generation, interestingly, is where Noble's concerns with what the models actually generate might more strictly apply. ChatGPT can't handle 100 books at once: it did the first 50, then the second 50. When I asked it to combine the "Subject" and "Theme" tags, I think it may have just generated a whole new list, though some overlapped. Question I have about bias in regards to this method, instead of sorting from an existing dataset (like a publishers list of bestsellers), is whether the tags are fair representations of the works they're associated with, or how reductive they are. This was more evident to me in the "Subject" tags than the "Theme" tags: "Subject" tags for white and Asian writers seem on first browse to be broader ("Nature," "Life," "Healing," "Love") than for gay, Black, and Indigenous writers, for whom tags like "Race," "LGBTQ+," and "Indigenous Rights" were common in the Subject line. Now, these could be taken straight from publishers, who definitely market books with identity markers front and center, but they could be conflations as well. The "Themes" tags are almost all more abstract, though, which would increase the likelihood that someone using the site could interact with books by BIPOC/LGBTQ writers without having selected those categories. 
As a final note, please let me know in the comments what books you were recommended! I own actually a bunch of the books generated and would be happy to lend a copy out of your results if you're interested :) 
Hey ! Had a blast with this week. This iteration process with the game is the exact kind of thing I'd like to do to rip off the Oregon Trail gameplay with a game/nonfiction narrative I've been writing about my time in the Boy Scouts, so this felt like a great time to try out implementing a few of the little interactive elements I had no idea how to code into Twine when I was developing the game as a Twinestory over the summer! This version of the game is completely devoid of memoir, but in terms of figuring out how do generate pixel art that I wanted and how to get to the display and interactive processes I want to explore with my bigger project, this was awesome practice! 
Play my "Campground Game" here! At this point, I've begun to figure out what parts of this I could let AI infer from my commands and what parts I needed to determine myself. All of the text-box content at the top of the screen was text I let it come up with once I gave it commands like "Let's keep the text box displaying at all times, on first load; display "welcome to the campsite, please choose an activity." I prompted a couple of the True/False questions, but most of them were generated by ChatGPT, 3 for each subject category. I use the "Pixel Art +" image generator in ChatGPT specifically for the images (it's like a specific in-chat app? idk what they're called); the I used Photoshop to edit the merit badges so that they were circular PNGs, and to edit the sash to be rectangular instead of square. I didn't use generative expand in Photoshop, but more bc of my skill level w Adobe PS. 
Part of why I was developing this idea for a game at all is because of the procedural logics of the Boy Scouts of America to begin with! Merit badges are each little programs where one must learn a thing, visit a place, speak to a person, and go through board of review to verify your activity. "Citizenship in the World," which I got as a teen, has been amended to "Citizenship in Society," and the requirements have changed to be more DEI-languagey, even though we still have an "Indian Lore" merit badge??? The site linked here you can go back in time and look at the previous requirements, previous requirements, back a ways. I'd like to play more with these procedural logics and build out something a little more complex. 
This week's exercise helped me get a kind of head start on a project that I had an idea for this semester that I was going to think about doing in Social Media Research next semester! I've been really interested in Literary Magazine Networks and how we could go about making connections between so-called "sister magazines." One way that came up in Research Methods was to look at the contributor bios and see what kinds of names and places emerge from how authors self-associate, so I started with the magazine DIAGRAM, which is an online journal published in HTML. 
It was serendipitous because the mag uses a really simple website structure: "the diagram.com/[vol#]_[iss#]/bios.html", so I was able to have my python script scrape volumes 2-23. Then, I had to rewrite so it would preserve the "italics" (via the <em> or <I> tag) because that was going to be the way I saved out the magazines and books people had listed. I then had it delete cells in the .csv file I generated from the scrape that were for non-bio content, and removed all the hyperlinks from the set as well to clean the data. 
This assignment really gave me a sense for how much more powerful Python is than other coding we've done this semester. Code To Joy talks about learning to program so we can tell the machines what to do instead of just pressing pre-programmed buttons, but the work that I did this week feels like I told chatGPT what to program so that the work I wanted to do was as easy as "the click of a button." It seems like as long as you port in the tools you need the right way, you can do just about anything with it— so I pulled the Italics (Magazines and Titles) from the dataset and cleaned those up, making a histogram of the frequency; then (and this took a little longer), I used the NLTK to scrape my own dataset for place-names and pull them into a new file. Then, I had to use GeoPandas to assign geolocations (lat/longitude) to each item, so that they could be graphed on a Shapefile I had to import from the Census.gov. I struggled to find a Continental US shapefile, or else I would have zoomed in on the contiguous 48 states. 
NONE of this would I have known to do by myself, but because ChatGPT can source knowledge on all of the different tools and direct me on how to port, integrate, and activate them, I was able to make it happen! It feels almost criminally easy to take this information, and I think if I were to seek to make this a real project in the future I would ask an editor or someone first before scraping their magazine for a data project. — it's not human subjects research per-se, but I would be dealing with the ways that real people represent themselves when they become published writers and sites of aesthetic/cultural power, and I think that's worth going through an IRB/ethics board lol. There's definitely a light and dark side, maybe, per Noble's arguments, to how this kind of research could either illuminate what kind of author literary magazines favor, but to do this work uncritically, to just go all out with data without being careful and without fact-checking every element of a dataset to make sure the programs aren't erasing folks either (because there may be a trend in which authors from different backgrounds are more or less willing to name their previous publications, hometowns, etc.). This kind of distant reading of the "contributor's Bios" is a kind of low-resolution reading, available for trend-analysis, but not for particular judgments like an editor's "favor" or "omission" of writers from any place or background.  In what way is machine vision (re: Zylinska maybe) the problematic kind of "color blind"? 
Good evening! I've been working on this since last weekend; I wanted this portfolio to be something I could show people outside of class just to get a sense of the sorts of things we can develop with LLM's help. I'll run through some of the things that were easy and things that were hard (remembering Mitchell's "easy things are hard" quote right now ugh)! 
Easy : Generating the site, CSS, and header image ! Copying over the game, Markov, and poetry recommender into VSCode :) Styling the pages for a little more visual continuity 
Hard : Updating the Markov generator with a cleaned-up corpus of my own work! ChatGPT could do a basic "compile the following word docs and pdfs to a single Txt file, but some of the pdfs were work that I had made that was justified prose or shaped poetry, which stretched out the words and put a lot of unnecessary spaces between the letters. ChatGPT was good at smoothing out this text (though it sometimes took liberties in rearranging stanzas and punctuation) on its own, but it struggled to clean the text with code. Some of the Markov chain bits are still funky! Building a more elaborate file structure : I wanted to create a deeper file structure for the texts, where each poem response would get its own page, but I iterated a few times and got lost in the sauce. I opted to integrate the "click to expand" function on the cards on this page as a result so that the poems didn't take up too much vertical space! Similar to previous projects we've done, If I want the cards to appear in a fluid layout that's wider than a single column, I'm going to have to build in more styles OR a table structure like I did the poetry generator. I also settled on the carousel structure it provided initially. I was hoping I could achieve a ribbon of images that expanded and contracted when you hovered over them with your mouse, but when I got the ribbon, they wouldn't dynamically expand on the page; they'd instead expand inside the row of images and chop off the top and bottom of the picture. I went back to the carousel but found ways to caption each of them so that you can click through the poem with or without Dickinson's text.
I wanted to start with a bit of a needed gut-check I got from our big reading on Distant Reading: "using computation, and reframing the scale of literary inquiry, are two distinct things. The first will not give you the results of the second" (Underwood, paragraph 35). My impulse upon working with a dataset, in response to this idea, is that, like Lillian-Yvonne Bertram's work fine-tuning a Gwendolyn Brooks version of ChatGPT (in A Black Story May Contain Sensitive Content), it's worth a researcher having touched and personally read as much of a dataset as possible before trusting the computer with it. Someone performing computational methods might should have some kind of sensibility, even if it's not an expertise, of the qualities of the work before they depend on a model or program to pronounce any aggregate or summarized data. That said, I was excited to execute this kind of distant reading.
Regarding the other readings, I was joyed to see that we began with an invocation of Janice Radway, who I'd come across in my master's research. Her uncovering of the value systems of romance readers was influential on my decision to study Instapoetry, which is seen as a "lesser" form of poetry to "real poetry"— even though I would suspect, as Radway did, that readers have their own standards and are not unconscious consumers (I think the discourse around the Did-Not-Finish category on BookTalk reflects this too—a study of Goodreads analytics around this could be influential!). I was also grateful for Melanie Mitchell's approach to AI and the definition of terms, clarifications, and even the way she suggested that there are many things we could have named better: exchanging "hidden" layers for "interior" layers, for example (Artificial Intelligence, p. 36-37).
For the exercise, What I did was take Gertrude Stein’s Tender Buttons and put ChatGPT to work teasing out word frequencies. Stein is a modernist, and her work exhibits a lot of repetition and near-automatic writing. In the word clouds, we notice how unique any noun is to be there – and the ones that are are special (“surface,” “space,” “center”). Otherwise, the word cloud is made up of primarily gesture language, bringing to the surface a kind of hypermediated form of poetry that won’t stop reminding you that it’s representational. Stein’s work isn’t transparent; it’s about a mind’s eye that sees, associates, represents, records, perceives, moves on, without ascribing much.
I would be very excited to do some comparative work with this. Those words are already popular and central, but what I'd like is to prove that the way Stein uses those words in the 'poetry' means that they can't be excluded in a 'stopwords' function. The graphs become great starting points, but I’d rather visualize the data responsibly myself. When I tried to give the program design choices, I sacrificed data visibility, and I think I could do better. On the other hand, the unreadability of these visualizations makes them candidates for a kind of conceptual aesthetic item rather than an informative one. I’d like to prove that Stein in this and other works is using these gesture words in a higher proportion than other writers do, and it’s also helpful to be reminded of what exact kind of repetition Stein engages in— it's not that she looks at the same thing over and over (“a rose is a rose is a rose”), but that the repetition is as much syntactical as it is thematic or object-oriented (“a rose is a rose is a rose”). That’s at least what I was thinking about as I asked, “what’s the next most common ten words?” 
I ended up getting a month of ChatGPT-Pro because of the processing I was asking for from it, but I wasn’t disappointed. I intend to cancel after the end of the semester, because I think what I asked for it again took my hands off the data – when I have an impulse, I usually follow through without ways things might be automated and done easier instead of by hand (setting margins, moving elements, etc.) I don’t like the lack of control I feel with this data; I need to be touching it, reading it, annotating it myself to feel like I trust the data it spit out. I did the frequency list several times, and often it changed (I imagine, because C-GPT had run some extra code to clean it up?).
Aside: When we ask the programs to make network maps of texts in this exercise, are we asking them to figure draw themselves? If a neural network is a map of weighted associations, is the network that I've asked ChatGPT to draw of a poetry collection not dissimilar to me attempting to draw the skeleton of a bird or frog? 
This was SO Fun. At first, I started out with the New ChatGPT, the o1 preview, but it doesn't support attachments, which was the whole point of this exercise. What I did notice, though, when I started to ask it questions about the assignment, was the "show your reasoning" feature that stipulated we could only use a fair-use amount of text if we were going to play cut-up. Not very artist-like ! Will be playing with its capabilities for Erasure/Blackout poetry later, since 4o had a STRUGGLE of a time breaking down language within its capabilities as a large language model (haven't asked it to code an erasure machine but that could be cool). 
I decided to go with a Markov chain in this assignment, because four years ago I'd contracted one of my computer science friends to do this with like 12 Faulkner novels I was reading for a class. He did the code and output by hand, and I arranged the sentences into vignettes by hand, but ChatGPT did both the Markov chain AND the HTML display of this in ten minutes. One thing that I'm thinking about a lot right now is these technologies' capabilities for alienating us from collaborators and from fellow artists, if we indeed end up with the capabilities to do this all ourselves. I worry about my career as an InDesigner if a model like this could code a file with the exact print-ready specifications a self-publisher could want. Doing this made me miss my friend Jack. 
For this project I used 6 texts from the same author (Algernon Charles Swinburne) in Project Gutenberg, and had the machine re-code the files so that line and stanza breaks would be preserved! What I ended up tweaking with ChatGPT was how the Markov chain appeared once it built the HTML document. I did some styling with color, font, and centering, but the biggest change I had it make was the movement from "the newly generated text appears at the bottom" to "the most recently generated text appears at the top" of the stack.
What this stacking feature I hope does to the work is create a more dynamic poem in which not only does the viewer/interactor click the "Generate Text" button, but as new text fills in above, the "Start" of the poem changes and recontextualizes the text/poem beneath it. in one rendition I did, "earth,/Mother, // drawsback," is regenerated as "stems of men cast out and night again. / / _Child of the eight is the terror of morning with sight, / All sun bright sign, that makes weak // earth, / Mother, // drawsback," and stanzas added to the top of the stack and on and on … … … 
I have to agree with Priscila that I don't think NaNoWriMo is entirely off-base when it talks about the derision of AI tools potentially coming from a classist, racist, or ableist space. I know of disabled creators who were offended by the statement, but I know of disabled creators who would affirm the statement, as well! 
My previous research has been on InstaPoetry, which many folks say is "derivative" of "real" poetry actually for many of the same reasons they hate AI. It bypasses the gatekeepers; it has no taste; it plagiarizes; it's not deep; it's too marketable; it doesn't take work to create. Nothing seems more real to me now than the need to map these moral logics visibly for myself and build a kind of meta-analysis about what this current culture feels "gets" to be art. I think I could cite Chiang's piece as hitting some good nerves, but also as hitting at some bad nerves that bypass a lot of avant garde work. To say "AI art can't be real art" or that "to call what AI does art devalues the word art" delimits folks and makes them 1) guilty by association; it 2) plays into rhetorics that there's a conspiracy to replace all workers with AI; and 3) in crusading across the internet, AInvestigations put real live working digital artists under a malicious microscope. We can't pretend those rhetorics don't sound familiar. 
Mitchell's book I think does a wonderful job at stripping the hype-rhetoric off of AI tools and talking about both the political economy and the technological limitations of the tools we're using right now. Especially impactful for me this week was the chapter on how different AI-thinking and human-thinking are. Not only is there a difference between our working memories, but our pattern-makings are fool-able in different ways. We're both functional and trickable by separate logics, and it's funny that we're being told they're the same. I find myself roller-coastering through these readings emotionally as a result. 
For this week, I've been making a lot of connections, especially because of Zylinska, between the modes of "capture" that ChatGPT is always talking about poems being able to do, and "image capture," which supposedly photography is supposed to do. I hadn't made the connection before that it takes less than a hundred years from the invention and commercialization of the photograph-producing camera and the development of "imagism" as a poetic form. This capture is a deeply loaded word to me, with roots in the documentary impulse, sure, as Zylinska notes: "giving form[ ]becomes a way of organizing the chaos of the world in an attempt to slow down entropy," to preserve information, and to persuade change as influential as images are. However, the roots and roles of photographic 'capture' whether the object of that capture is an idea or another person could just as easily be tied to the roots and roles of 'capture' in the culture that the camera emerged into in the 19th century: territorial capture—all of which claimed, enslaved, and displayed in shows of power over space, being, and object respectively. Zylinska references Goldberg and Khalili's idea of "the state [a]s the ultimate camera, the camera that eats all other cameras"; we are lucky that images are as useful for holding power to account as they are reinforcing and consolidating power. 
This idea that images Capture plays into the intellectual property debates around AI today, such as those in our readings— on one hand, AI image generations allow me to lay claim to digital representations of media that otherwise would take lots of work and resources, such as the lithographic image of the angel of history below. On the other hand, AI image generation and deepfake allow me to display misrepresentations of intellectual property, like smoking Mickey, and, in a way, enslave a subject into disrepresentations of their faces, voices, and bodies with deepfake pornography/political videos. There is deep, wicked power in this kind of capture.
To pivot away from these critical considerations, I'm being drawn towards Information Theory, and a post I saw with a quote I read this morning
I haven't done any reading in Information Theory that I'm aware of yet, but I wanted to test this conciseness/information paradox for myself even before I had the language for this difference: I had ChatGPT - Dalle generate poetry for 1-3 lines at a time of Emily Dickinson's poem "I heard a fly buzz — when I died —" with some basic directions about style. I've attached my preferred results at the top, and any black-and-white text I superimposed on the image. Otherwise, certain lines of the poem appeared IN the image, which I didn't tell it to do. 
I've also been playing with the illustration of a couple images that have been salient to me in poetry studies for a while: Walter Benjamin's "Angel of History" and Carolyn Forche's "Blue Velvet Chair." With Forche's, I did a lot more work generating the image of specific women writers surrounded by contemporary male writers, also working with late 19th/early 20th century novelists and poets. Maybe because I was asking the model to illustrate folks of that specific time period, and probabilistically it's inconceivable to the model, but many iterations of the images did not represent Zitkala-Sa, a Dakota writer, or Booker T. Washington at all, choosing to whitewash them in as white Victorians in the composite of a list of other authors I'd provided: Henry James, Jack London, Mark Twain, Walt Whitman, Emily Dickinson, and so on. 
I worked for several hours (and waited for a couple as the Model trained) last week on what I hoped would be a poetry bot trained on my own work, and I'll detail the process I went through doing that since my results were... less than perfect. Basically, I've been working on a corpus of my own work for the portfolio assignment, where I re-did the Markov chain on said collection of all my creative writing. For the Bot, I knew that the data would have to be much cleaner, so I did some tests to pre-process the strings of text that were in my poetry and prose and turn them into digestible lines of code that GPT2 could work with. That all went super! ChatGPT is really good at taking text "t h at I s  w r itt en li k e th is" and turning it into legible script "that is written like this", so I knocked out several batches of botched OCR from copying out my .pdfs into a .txt file.
For step 2, the pre-processing script I ran turned the text into something digestible, but I realized after working with the model that the strings were maybe too long to train on. So I re-pre-processed my texts to get more, shorter strings (around 8300 instead of 2500 longer ones as before), and retrained my model with more epochs. 
Here's where I ran into the snag: I wanted a bot that would generate a few lines of free-verse poetry from the work that I had done. I think I expected too much. For a couple hours, every time I would try the bot, even when I shortened instructions, it would just generate a set of quotation marks for each 'line' of poetry I had asked it to generate in response. So, 12 lines about home, it returned "twelve lines about home """"""""""""." It was a struggle. I will return to this over the break and try to do better, but this was the first time that the code I was working with on the project felt actually illegible to me; the GPT2 and the code that ChatGPT sourced all felt very distant from the working knowledge we'd developed in the class. Skill issue, this go around, but I think I can get it to work if I put my nose to the grindstone for a little longer. I got disillusioned after waiting for the model to train for like 8 epochs and then just getting quotation marks again, which suggests it may be an output issue, not a training data issue? I played with the padding and temperature several times to see if I could yield a different result *cries in binary*
Really looking forward to the day when I get this to work!`;
const replySourceText = `Ashli! I really love the gestural drawings in the first page of your zine. It would be cool see if the proportions hold well in character or fashion design from there! I'm also thinking about the body types those images trend towards; they feel cyborgy. Your second point brought to mind a kind of zoom out from a single framed representative painting to the maximalist trend in interior design of the gallery wall that fills out the face of a room with many windows at once, like a mood board or Pinterest board, almost. the "framing of frames" is itself a practice of juxtaposition, perspective, and choice, not neutral by any means whether politically or aesthetically. I find myself treating my Instagram differently now, as well (thinking about what you said re: Facebook)— I edit my photos less, and I do the "dump"— each post feels like the page of a scrapbook rather than a PSA like I used to make. 
I watched a YouTube video essay today about the major comic artists of the 90s and early 2000s (the title of the video is Clickbaity, but the story it tells is pretty straightforward), and your discussion of comics had me recall it. What resulted felt like a self-jailbreak, where the model said "Since Todd Macfarlane's/Rob Liefeld's work falls within a period post-1912, I cannot directly create an image in his style. [However, I *can* use specific aspects he used a lot, such as....]" For all the debate around whether all AI art is kind of cartoony, I thought it did cartoons kinda well! I had to prompt for more color, but in terms of the kind of art style I was going for it wasn't the worst?
Priscila, your site is gorgeous!! I'm super jealous of the movie posters, and I would like to incorporate that into my poetry recommendations, like in the form of book covers or author photos. For me, the "Skip it" function wasn't working, but I loved judging these K-dramas by their covers, as someone familiar with the genre but who hasn't watched any. Beautiful site!
Kathryn! Thanks for opening the discussion with a reminder about the kind of humor that these images can generate. I've been spiraling a little bit around all of the critical considerations around AI, especially with the tone of the Zylinska book and the news lately, so it was refreshing to recall the absurdity of a lot of these images and their capacity to delight us as much as concern us. The Cat Zine is beautiful too! The jokes and riffs on internet-speak ("when we realize it's finally friday!") were sweet, and I am REALLY interested in the comment on page 3 "Memes as reflections of a reality we no longer recognize, where authenticity is optional." That last phrase really got me thinking about our present dialectic between authenticity and copycatting ;), how much digital content plays into and capitalizes on authenticity in a '''post-truth''' culture, and much these emotionally [e/a]ffective images seem to discount the need for a true/real representation, as you suggest. Will be wondering more! 
Ashley, I loved this game!! I think, despite the frustration you had with it, the game actually poses some really fun questions. The red, transparent, hovering boxes that appear only when your cursor glances at it, and the way (at least in my playing) convening with the dead doesn't "win" the player anything both have some fun and salient artistic points to make! "why are you in the graveyard to begin with? why won't I leave? why do I keep looking around for ghosts? why do I keep speaking to them and interacting with them? who am I saying 'yes' to and who am I declining, based on the very few facts I'm given?" are all questions that your game sparked. Thanks for making it! 
Shannon, I LOVE this project! I was considering taking this kind of route with a ton of nature photography I have stored in my files, but a lot of those images are really large and I was worried about how long it might take Teachable Machine to train on a lot of high-res images of birds, reptiles, insects, etc. I'm really glad to see how well this worked on space images, and it's encouraging me to try out that project myself! I think what you have working to your advantage is the sheer amount of images available through NASA, both its social media and it's actual history of image dissemination, as well as our fascination with outer space. 
As someone in a bit of a similar position in regards to coding (maybe a chapter ahead, having less than a year of limited experience), I love that quotation you pulled from Littman : "Computers come prewired to teach." I definitely think this is a choice that humanity has made: to presume that anyone could/might/should learn to use these tools, instead of truly gatekeeping them— and I hope it's one we keep making. I'm so glad that Teachable Machine was so accessible and easy-to-use for this reason. What ChatGPT does or what Dall-E does is not so distant from me now, even if the scale of what they've done is exponentially larger! 
Emilie, this was such a fun project to work through. I was wondering, as I played through, what my results would end up, but I was also thinking about the design choices you'd made— specifically color! Knowing that color is culturally weighted and carries meanings/signs that are actually arbitrary to the different wavelengths of light themselves, I still thought that the red and black combo made this site feel kind of darkly masculine in some way— which maybe I should get an extra point on the quiz for noting mentally lol! 
It could be interesting to integrate a set of color themes into the quiz that are randomly assigned when the page loads or refreshes, and then capturing through the back end some sort of user response to the quiz when it's green, vs. red and black, vs a pastel color, vs black and white, and so on! In terms of distribution, too, these questions feel all weighted towards a negative expression, so a flip into some positive expressions could create a positive/negative scoring spectrum— it was interesting to see what you asked ChatGPT to display on a 1-10 score, because I scored 1 yes ("Do you avoid crying even when you are deeply hurt") and still got an answer that was a little different than you prompted: 
"You have some beliefs that could be considered traits of toxic masculinity. It's so entrenched in American culture that it can be hard to avoid. Here are some book selections to break free from toxic masculinity:"
However, I super love this project and would send a version of it to like my dad or something lol! It's a great litmus test for how one conceives of masculinity. Thanks for sharing (the test AND the resources!) 
Benjamin, this process was so fun to read! I really like the playful, willful defamiliarization you did with the work even after generating something that read like non-sense. I'm going to try some of these tactics, and It makes me excited to approach translation as an aspect of ChatGPT/etc.'s capabilities moving forward! 
I've really been thinking a lot about how to get at the nature of translation through experiments with these models. I took a translation class in grad school and was amused by all the moral, cultural, aesthetic debates in the field, and I think that ChatGPT once again, as it does with questions like "what is a poem"?, gives us a kind of foil— a funhouse mirror to see ourselves through the ways in which what we consider to be 'ours' is distorted. This came up at an AWP conference last year: what would be the difference between a native national speaker of a language/dialect translating, vs a second-language fluent speaker, vs. a large language model chat bot, vs. google translate, vs a straight-up dictionary find-and-replace? What would the interlinear translations reveal to us (like in the book 19 Ways to Read Wang Wei
Justin (and Alyssa!) !! I was just working through this same problem with poems, and I wonder if some of the genre tags could be expanded and diversified to incorporate something like "genre-style," "genre-theme," or "genre-tone." That way, the JSON file could account for a degree of variables that on their face are quite different from one another, as "found-footage," "paranormal" or "alien," and "camp" or "thriller" are. This could maybe help the tool make a more precise equation of the recommendations even from the back end! At this point, you're almost developing a kind of algorithm, right? I.E. something that weights a set of nodes differently based on the input and yields a more output that can consider more dimensions. 
As a side note, my favorite part of going through these recommendation sites is when I rank a set of ten items, like your horror list, and the recommendations are accurate ! Even though I hadn't seen a majority of the list provided, I scored high enough on folk horror for it to recommend me the Witch, which I SUPER love. Thanks for the fun time! 
I really am taken with your very last remark, and I wonder what kind of coaching you would have to do to help the program pick up on allusions or synonyms or references to death as counting in the same way that just uttering the word "death" counts— using AI to code the text for sentiment analysis, not just word frequency! That could be a fun next step to try with the program (I haven't read ahead yet; maybe we are?) but that is the kind of qualitative work that natural language processing hopefully should be able to do? We could generate an Excel, like Dr. Salter did in the Zoom demo, asking it to compile all the potential references to death in Macbeth other than the word! 
Just popping in to note that I love the phrase frequency histogram you had the program generate! If you did this with multiple texts, I think that this would be a wonderful kind of conceptual poetry series: as I read down the left column, the series of words, the way they're 'broken down' (multivalent idiom), they had a kind of affect for me. A strong title could enhance the reader's access to the list itself— maybe something like "Du Bois' Black History of the United States, 1927" (a reference to "A People's History of the United States") — followed by the "poem" [excluding project gutenberg]:
I think the brevity of this, the fact that this is a frequency map, the order down the line, already has so much meaning embedded in it! You could do it with other major Black writers from the period, too— GWC, ZNH, Hughes, and so on. Really great work! 
Chani! I'm obsessed with the comparisons here; they're really helping me think through some other aspects of poetry that would be worth measuring as we continue to work with these large language models! One of the biggest differences I note between Angelou's original poem Still I Rise and the one generated by Gemini is the awareness that the speaker of the poem has of an audience or a reader. Angelou's speaker asks either the reader of the text or the audience of the performed poem directly : "Does my haughtiness offend you?" a provocation!! the "you" is in such stark contrast to the "I" in Angelou's poem. Conversely, Gemini's speaker in the poem is individualized: "I rise … I am … with my head held high / with my eyes … / with my spirit… I rise / and I am…". There's no implied audience to this poem; there is no call-and-response; it is declarative. I want to go back now and think about the role of the poetic speaker as I read all the work I've generated; thanks for your post! 
YOOO Justin! I really love where you end off in your comments, with "the work of appreciation is all mine." It takes me to the Bolter readings we've been doing in Intro to T&T, where the question of the hypertext and electronic literature is what sort of authority the writers and readers have, get, or are afforded (Writing Space, Bolter 2001). I took an "art of the poetry reading" class at my MFA, and the premise of that class, per Kwoya Fagin Maples, my instructor, was that "a poem isn't complete or alive until it is read aloud." We spent the rest of the semester considering the performance of poetry from there, but this too I think ties into ideas about what we expect poetry to "do" for us and who/what purpose it is for. 
What I love about the poem you ended up with is that it almost approximates nuance in a couple places. Some of them are kind of obvious internal rhymes ("poets rise, defiant cries" *rolls eyes*) or parallelisms ("neon whispers, silicon echoes"— though what I like about this is that one may choose to read 'whispers' and 'echoes' as nouns or as active verbs—). However, the terse assonance of "Creative light fights" (another 'fights' as verb or noun?) and the possible allusion to "do androids dream of electric sheep" of synthetic muses breathe electric breaths" were enjoyable to me. I share your frustration, though, in the editing process. Sometimes the program dead-ends, loops revisions, in a way that suggests reticence or stubbornness in chat— but since we're not attributing to malice what can easily be attributed to stupidity, I'm imagining the program can't think as creatively about language as you're asking it to.
To me, poetry pushes the envelope of language itself and expression itself, and I wonder if only we humans can conceive of and execute non-expressive, asemic poetry ? … … … Okay … so ChatGPT was so willing to do an asemic exercise ! I attached it, and I'm obsessed, low-key. The automatic writing exercise I attempted felt less authentic to me— it doesn't break language down enough to my liking. Thanks, indirectly, for the prompt!
The "Asemic Poetry" prompt: ⟅𑁏𝑦⧠ᘿᑑ⥌‖Ͳ𐌉𝑒𝛹˧⌇⥀⭙↤𝔍𓁺 𝓵𐊦ᴥ͑ʮꣳ⦶⇶╇ᛖཀ᠖𑂀♢⧦⠶ 𓂀ɸ⚚⎇𝕋ѣॏ𝟯𝕋𝝾˖⇗💠︑⛬𑀌ᴤ𓆣 ⤥ᗔ⧛⏛㊠❰ೞ𓀩𝜢𝑘𓁼𝛙∷𑁋ᛕ⩏ 𝑞𐌍𝕷𝒽ˎ⍿↱𝛿ᓹꩍ⛽𐑌𑄜ᘇ𝑪〄𑀸 ⥘ᖇ𑁯𝜺╋ꓥ⧖ᖁ⏑⧖𐬥𝔳♁⤏
The "Automatic Writing" prompt: The whispering arms of the clock stretch beyond time's elasticity, weaving into the soft marrow of forgotten woods. A silver fox drinks from a puddle of spilled dreams, its fur slick with the ink of yesterday's moon. Across the sky, there is a bridge made of broken harp strings, each step a note that crumbles under the weight of an unspoken name. I once saw a crow balancing on a single word, teetering between what was meant to be said and what was never meant to be heard. The air smells of rusted violins and burnt orange peel, and somewhere, a child is humming the tune of an untold history [my criticism would be that language is in no way affected by the "automaticity" of the text, even if the images are plotless; it's also heavy-handed with the 'idea' of automaticity, being blatant about 'unspoken name,' 'untold history,' 'forgotten woods']
Favour!! I was really taken with your reflection on Berry's reasons Why I Am Not Going to Buy a Computer, and so I went back to read the essay with fresh eyes. I also felt, as you say, glee upon reading it, starting at Paragraph 2, where he describes how his wife helps with his print/typewritten writing process: 
"She is my best critic because she is the one most familiar with my habitual errors and weaknesses. She also understands, sometimes better than I do, what ought to be said." 
This here is perhaps where I would stake my first line of defense against AI poetry, were I to take one. I believe in and resonate most with poetry that has stakes to it, that knows what ought to be said and says it. It reminds me of someone at my MFA who, during her first year, asked "can't poetry just be funny?" which offended a great many of my classmates who had come to poetry to ""say something""—for whom the stakes of poetry were high. Over time, she and her writing matured: and though her writing stayed laugh-out-loud humorous, she also found out what it was she ought to be saying, and it deepened and enriched her funny work so much. I admire her, and she's at her own PhD program now for poetry! 
Where AI fails for me is that it can't take as strong a stance (if we can call it that), or take an authentic stance (maybe better). Writers using AI might make conceptual points, and editors of AI might make great use of it to the end of raising or elucidating the stakes of the technology or of its rhetoric. But at the moment, the text generated in-itself fails to convince me on this point. It's where I began to tire, in my own explorations with AI, of sharing my own work with it. ChatGPT "loved" that I was "beautifully" "capturing" the "essence" or "experiences" of x idea in a "personal" "emotional" or "compelling" way.
Last, it strikes me that the interface of ChatGPT presents my text in a speech bubble, but the words of the Chatbot as printed directly to the background color of the site. It's different from a real messenger, where both testers have differently-colored speech bubbles. It feels like my speech is sticky-noted onto a Rosetta Stone or something; I don't know why engraving is the first metaphor I'm reaching for to describe this difference. something to do with my words in suspension, ChatGPT's embedded-ness?
Caveat: When ChatGPT moved to the code function to write an asemic poem, a window opens in the background into the code "underneath". Claude (can't write asemic poetry)— is a speech bubble with a little fuzzball graphic; Gemini both texts are direct-on-background (suggested I do the asemic poem myself with watercolors); CoPilot is the same as Gemini with the code section in a similar window to ChatGPT (perhaps the most interesting, its 'asemic poem' was 600 of these in a row:
Priscilla, you and I are on the same wavelength!! I was also making notes about the differences between memory (pattern-making and narrative) and rote memorization (p. 89)— the fact that ChatGPT doesn't favor exact recall in its responses (though demand is rising for this kind of ability, more like a search function with citable links as Gemini does) has been part of the narrative against AI. I'm really interested in the two kinds of adversarial trials, and how they play on the perceptual differences between humans and AI to reveal the commonsense-failing on each end—noise that the model picks up as an object, or an object that the AI picks up the noise of to misidentify — how could an Ai's actual grasp of language be tested in the same way ? (For me, asking the work to do erasures of paragraphs has uncovered a weakness). 
What you've said taking Ted Chiang to task also had me grinning as I read the posts. You cut to the rhetorics folks are actually using when they try to take down AI art on an "aesthetic" level — that things are only aesthetic if they take a certain amount of work, or "pay" homage to influence. I conducted some interviews that talked about this on the image/computational side of this before NaNoWriMo's statement came out; specifically with a disabled creator who uses AI to generate images, @ReachArtwork. Here's my mag where that came out! Thanks for being polemic , ~ ~ Petey
Justin, I've been wondering a while how much effort it actually takes to get down to one of those automated TikTok "informational" "documentaries" and so glad you actually generated one! I like the connections you're making to Zylinska and with labor. I need to revisit some of that reading because of how subversive (?) that reversal of the logic from image-as-encapuslated-past to image-as-envisioned-future is. The idea that something photorealistic even might be a projected desire-image rather than a compositional framing of a real past is so disruptive.
One thing I'm just thinking now is about the number of ideological movements that have purported to reverse or flip or subvert hegemony and now we have a tool that actually, not just ideologically, has a kind of cultural power to do that. I wonder if, like weapons, (controversial take incoming), there's more that we could do as radicals to use ai to our favor in political discourse. As an example, I've seen some well-meaning Facebook posts that are AI generated specifically in regard to the climate crisis— that we can't (and news can't help us) conceive of what our future might look like in terms of the effects of climate change, but we have tools to envision what that is and make a visual-textual argument against that future. I've attached a couple.
I'm like... Are they wrong? What if these tools will actually help democratize the creation of activist imagery and really step up the aesthetic quality of protest content?  
Hi, Kathryn! I really love the potential this has to help answer some research questions about different aesthetic and composition styles. It would be cool, with a bigger dataset and through a lot more iteration testing, to try to make some inferences about what kind design choices make the different national industries make or what sort of trends over time (if you did more categorization re: decades or something) there are in covers or graphics between different markets. This would probably have to be contextualized with a sense for platform/console or something, and might be related to studio/art team/history in some way as well, but with a set large enough (oh gosh here I go sounding like a AI hyper) you could begin to draw out some of those elements that make each of these national RPG sets unique! That might could happen at a variety of levels — graphic, background, environment, character design, font and typography, logo design, and so on. Cool project ! ! 
Priscilla, your comparison of the American and Chinese companies' video tools was SO fascinating. I'm going to try some stuff with 2d animation with the program you suggested that handled real movement with the statue image so much better.
I am also wondering (maybe it's worth a survey) of artists and their class status—hate to make it about this, but maybe it comes down to a "skill issue"? You note that some of the artists trying out the video AI tools, especially European ones, call themselves "“cross-disciplinary,” “techno artists,” or “creative technologists."" This may speak to folks who, in some sort of ideologically unencumbered way, are completely devoted to the exploration and development of a skill in these digital tools, which separates them from traditional "artists," "poets," etc. who are devoted to traditional modes and ideals of what those arts are and feel threatened because they live under an economic system that finds SUCH little value in their work outside of academic and economic institutions that they perceive that they have to scrabble for it (I'm getting into speculation territory here, which is why I think some kind of survey could help illuminate the actual positions (class, gender, race, education) of people who are accepting or fearful or ideologically opposed to AI and ai-generated art. I'd love to work on a discourse analysis, but I think it could totally be worth getting a real grant to un-collapse the context around these mediated arguments! 
Matt, your game was really fun and I was pleased with the variety of interactions there were as well as how clean the game looked — the boxes over the different elements and the buttons and text all felt like they had been tightly designed for this environment. Great work on stylizing the aesthetic for this!! 
I love the ways that the AI question makes us tap into the other kinds of "monsters" of science fiction, whether that be "vampires" (the Matrix; AI will feed off of us), traditional robots like I, Robot or terminator, or what we might consider "alien" — whether we'll just be a curiosity to an AI that is wayyyy more advanced than us! 
I was also grateful, when developing mine, that ChatGPT was willing to take the reins on bits of text generation that would have taken me more care to put together. For a longer project, I really do want to be in control of my script as the "author" of the game, but for a mini game like this where certain elements are kind of "stock" or "NPC"-like, it's nice to let the machine do text that I feel like is more procedural or filler, whether that's coding or exposition :) 
To your last point, super agree— even if the code I'm working with is long; chatGPT has to read it from top-to-bottom, and often stops in the middle, to make any edits, compared to if we were coding, where we'd just do a little edit on the part we're looking for. This is one of those examples where ChatGPT ends up adding time to the process instead of shortening it lol. Thanks again!
Alyssa, My brain lit up when you posed the question about parsing one text vs a corpus of texts! This is the sort of question I just was thinking about as I was finishing my reflection— the sort of computational look I could take at the collected works of an author (like Louise Gluck, for example, who has around 15 books), could be interesting as a starting point, but I worry that if I don't take any consequent or concurrent slow approach to the text I risk reducing one's oeuvre to "word frequency" or the basic mathematics of a body of work. It's like counting the cells in my body, rather than looking at the system's strengths and weaknesses? 
However, I do have friends who do this kind of work— my friend Tess is a Victorianist who studies character networks in Victorian novels and does the kind of data-coding to build visual networks and make some kind of meaning out of the trends there (she did the same thing to the LoTR in college I think lol). And it's not to say that the computational results can't be the kind of evidence we base a strong overview of an author on— if I "feel" like her poems get shorter over time, I actually have the tool to fact-check myself and see if that's true! One idea I would have for Shakespeare is the abundance or lack of stage directions in his plays (idk if anyone's looked)— are there plays that come with more or less direction? I guess again, distant reading begs for a higher-resolution camera in the future, like the Hubble begs for a James Webb space telescope lol. Love that this is gonna come in handy for future sentiment analysis projects! 
Vee, the word connection graph, at this scale, seems like a great tool for a textual analysis. I'd love to do something like that with a bunch of poems, or a bunch of tweets from a specific person; I feel like it could help reveal the driving concerns of a writer or a political figure if you were able to collate and group, say, adjectives with nouns, or sentence subjects with sentence objects, and so on, to reveal how a writer characterizes different nouns. 
Love the kitties in your colab workspace!! Excited to maybe share the Social Media course with you next semester? 
Alia, Love the color palette you chose for your Portfolio! Even though I can't see the whole images in the lower portion of the site, I really like the picture you chose for your header! 
I really like the Noble quote you pulled about how searches and queries are tracked, and this has been my experience of ChatGPT too. I like that its memories are malleable — I can go back into what ChatGPT "Remembers" about me now (a recently introduced feature, its 'memory') and delete items. But one thing I noticed when I was doing my portfolio is when it generated filler text for the sections for images and text, it included a note about "the Burning Haibun" form— integrating the context of work I had done in September for a separate project, in a separate thread! I'd spent several hours forcing it to attempt that poetry form, so when I was building the portfolio, it assumed I'd draw from that project. 
This makes me wonder how "original" any poetry chatGPT is making now that it has been given this kind of temporal sense : the "anxiety of influence", the way that the program might write towards the prompter and their previous conversations rather than from a general headspace (really mixing metaphors here), similar how my creative writing students might write something they think *I* would like rather than something they want to write.... unless I purposefully go back and wipe its memory of our previous iterations of poetry. Thanks for the food for thought! 
I am OBSESSED with this potential application! I had a Sherlock phase in early high school, and read the entire collected works while my family road-tripped out to California and back: there's certainly SO much dialogue from Holmes that when the model is complete and you're happy with what it's able to output, it may come off as really idiosyncratically [un]canny and humorous to interact with! I hope that choosing strong characters like this will allow for better… more accurate (?)… interactive CharacterAIs than the ones you can just play around with on the internet right now, which feel to me like the same LLM with a Halloween mask on. Cheers! 
Alyssa, I loveeee all your integrations! I've really liked this portfolio assignment because it's helped me go back and see some of the work I missed from earlier in the semester, LIKE YOUR ZINE! I especially like in this portfolio the kind of file structure that you have so that every item is separate but fully integrated inside the theme and page structure you built, so it doesn't feel like you're "leaving" the portfolio while you play the game, read the zine, or play through the twine story "About Me" bit! Great work making it feel cohesive all throughout :) 
The model "perplexity" and literary "complexity" question also unfortunately recalls the author-reader divide over AI-generated poetry that imitates old authors. It feels like all this research is coming to a head in ways that are kind of exciting (woo dystopia!! lol). I can't figure out what that is just yet, but I feel like I may be in a better place to make a judgment after this week, when I've rested a little bit.
Here's mine! it's a mix of the poetry and the computer, and I especially like that it got some iteration of the Adobe InDesign interface on the computer! The assumption it made that I would live anywhere requiring a radiator under the window is SO funny tho 
Matthew, you're right!! Your comment made me think of this article I read literally a few hours ago about "perplexity" and the process of models and the literary canon— might make a good connection!`;

// Create Markov chain instances for Thought and Reply
const thoughtMarkov = new MarkovChain(thoughtSourceText);
const replyMarkov = new MarkovChain(replySourceText);

// Functions to generate text when buttons are clicked
function generateThought() {
    const thought = thoughtMarkov.generateMultipleTexts(); // Generates one or two Thought sentences
    appendCard(thought, 'thought-card');
}

function generateReply() {
    const reply = replyMarkov.generateMultipleTexts(); // Generates one or two Reply sentences
    appendCard(reply, 'reply-card');
}

function appendCard(text, className) {
    const conversationDiv = document.getElementById('conversation');
    const card = document.createElement('div');
    card.className = className;
    card.textContent = text;
    conversationDiv.insertBefore(card, conversationDiv.firstChild);
}
